CONTEXT-FREE GRAMMAR (CFG)
--------------------------

A context-free grammar is a 4-tuple (V,Σ,R,S), where

  1. V is a finite set called the variables,
  2. Σ is a finite set, disjoint from V, called the terminals,
  3. R is a finite set of rules, with each rule being a variable and a
     string of variables and terminals, and
  4. S ∈ V is the start variable.


DESIGNING CONTEXT-FREE GRAMMARS
-------------------------------

As with the design of finite automata, the design of context-free
grammars requires creativity. Indeed, context-free grammars are even
trickier to construct than finite automata because we are more
accustomed to programming a machine for specific tasks than we are to
describing languages with grammars. The following techniques are
helpful, singly or in combination, when you’re faced with the problem
of constructing a CFG.

First, many CFLs are the union of simpler CFLs. If you must construct
a CFG for a CFL that you can break into simpler pieces, do so and then
construct individual grammars for each piece. These individual
grammars can be easily merged into a grammar for the original language
by combining their rules and then adding the new rule S→S₁|S₂|···|Sₑ,
where the variables Sᵢ are the start variables for the individual
grammars. Solving several simpler problems is often easier than
solving one complicated problem.

Second, constructing a CFG for a language that happens to be regular
is easy if you can first construct a DFA for that language. You can
convert any DFA into an equivalent CFG as follows. Make a variable Ri
for each state qi of the DFA. Add the rule Rᵢ→aRⱼ to the CFG if
δ(qᵢ,a)=qⱼ is a transition in the DFA. Add the rule Rᵢ→ε if qi is an
accept state of the DFA. Make R₀ the start variable of the grammar,
where q₀ is the start state of the machine. Verify on your own that
the resulting CFG generates the same language that the DFA recognizes.

Third, certain context-free languages contain strings with two
substrings that are “linked” in the sense that a machine for such a
language would need to remember an unbounded amount of information
about one of the substrings to verify that it corresponds properly to
the other substring. This situation occurs in the language
{0ⁿ1ⁿ|n≥0} because a machine would need to remember the number of 0s
in order to verify that it equals the number of 1s. You can construct
a CFG to handle this situation by using a rule of the form R→uRv,
which generates strings wherein the portion containing the u’s
corresponds to the portion containing the v’s.

Finally, in more complex languages, the strings may contain certain
structures that appear recursively as part of other (or the same)
structures. To achieve this effect, place the variable symbol
generating the structure in the location of the rules corresponding to
where that structure may recursively appear.


CHOMSKY NORMAL FORM
-------------------

A context-free grammar is in Chomsky normal form if every rule is of
the form

  1. A → BC
  2. A → a

where a is any terminal and A, B, and C are any variables —- except
that B and C may not be the start variable. In addition, we permit the
rule S → ε, where S is the start variable.

Any context-free language is generated by a context-free grammar in
Chomsky normal form.

PROOF IDEA:

We can convert any grammar G into Chomsky normal form.  The conversion
has several stages wherein rules that violate the conditions are
replaced with equivalent ones that are satisfactory. First, we add a
new start variable. Then, we eliminate all ε-rules of the form A→ε. We
also eliminate all unit rules of the form A→B. In both cases we patch
up the grammar to be sure that it still generates the same
language. Finally, we convert the remaining rules into the proper
form.

PROOF:

First, we add a new start variable S₀ and the rule S₀→S, where S was
the original start variable. This change guarantees that the start
variable doesn’t occur on the right-hand side of a rule.  Second, we
take care of all ε-rules. We remove an ε-rule A→ε, where A is not the
start variable. Then for each occurrence of an A on the right-hand
side of a rule, we add a new rule with that occurrence deleted. In
other words, if R→uAv is a rule in which u and v are strings of
variables and terminals, we add rule R→uv. We do so for each
occurrence of an A, so the rule R→uAvAw causes us to add R→uvAw,
R→uAvw, and R→uvw. If we have the rule R→A, we add R→ε unless we had
previously removed the rule R→ε. We repeat these steps until we
eliminate all ε-rules not involving the start variable. Third, we
handle all unit rules. We remove a unit rule A→B. Then, whenever a
rule B→u appears, we add the rule A→u unless this was a unit rule
previously removed. As before, u is a string of variables and
terminals. We repeat these steps until we eliminate all unit rules.
Finally, we convert all remaining rules into the proper form. We
replace each rule A→u₁u₂···uₑ, where e≥3 and each ui is a variable or
terminal symbol, with the rules A→u₁A₁, A₁→u₂A₂, A₂→u₃A₃, ..., and
Aₑ₋₂→uₑ₋₁uₑ. The Aᵢ’s are new variables. We replace any terminal uᵢ in
the preceding rule(s) with the new variable Uᵢ and add the rule Uᵢ→uᵢ.


PUSHDOWN AUTOMATON (PDA)
------------------------

A pushdown automaton is a 6-tuple (Q,Σ,Γ,δ,q₀,F), where Q, Σ, Γ, and F
are all finite sets, and

  1. Q is the set of states,
  2. Σ is the input alphabet,
  3. Γ is the stack alphabet,
  4. δ: Q × Σε × Γε → 𝒫(Q×Γε) is the transition function,
  5. q₀ ∈ Q is the start state, and
  6. F ⊆ Q is the set of accept states.

A pushdown automaton M=(Q,Σ,Γ,δ,q₀,F) computes as follows. It accepts
input w if w can be written as w=w₁w₂···wₑ, where each wᵢ∈Σε and
sequences of states r₀,r₁,...,rₑ ∈ Q and strings s₀,s₁,...,sₑ ∈ Γ∗
exist that satisfy the following three conditions. The strings sᵢ
represent the sequence of stack contents that M has on the accepting
branch of the computation.

  1. r₀=q₀ and s₀=ε. This condition signifies that M starts out
     properly, in the start state and with an empty stack.
  2. For i=0,...,e−1, we have (rᵢ₊₁,b) ∈ δ(rᵢ,wᵢ₊₁,a), where sᵢ=at and
     sᵢ₊₁=bt for some a,b∈Γε and t∈Γ*. This condition states that M
     moves properly according to the state, stack, and next input
     symbol.
  3. rₑ∈F. This condition states that an accept state occurs at the
     input end.


PUSHDOWN AUTOMATON IS EQUIVALENT WITH CONTEXT-FREE GRAMMARS
-----------------------------------------------------------

  1. If a language is context free, then some pushdown automaton
     recognizes it.

  2. If a pushdown automaton recognizes some language, then it is
     context free.

Because every regular language is recognized by a finite automaton and
every finite automaton is automatically a pushdown automaton that
simply ignores its stack, we now know that every regular language is
also a context-free language.


THE PUMPING LEMMA FOR CONTEXT-FREE LANGUAGES
--------------------------------------------

If A is a context-free language, then there is a number p (the pumping
length) where, if s is any string in A of length at least p, then s
may be divided into five pieces s = uvxyz satisfying the conditions

  1. for each i ≥ 0, uvⁱxyⁱz ∈ A,
  2. |vy| > 0, and
  3. |vxy| ≤ p.


DETERMINISTIC PUSHDOWN AUTOMATON
--------------------------------

A deterministic pushdown automaton is a 6-tuple (Q,Σ,Γ,δ,q₀,F), where
Q, Σ, Γ, and F are all finite sets, and

  1. Q is the set of states,
  2. Σ is the input alphabet,
  3. Γ is the stack alphabet,
  4. δ: Q × Σε × Γε → (Q×Γε)∪{∅} is the transition function,
  5. q₀ ∈ Q is the start state, and
  6. F ⊆ Q is the set of accept states.

The transition function δ must satisfy the following condition. For
every q∈Q, a∈Σ, and x∈Γ, exactly one of the values δ(q,a,x), δ(q,a,ε),
δ(q,ε,x), and δ(q,ε,ε) is not ∅.

The transition function may output either a single move of the form
(r,y) or it may indicate no action by outputting ∅.

To illustrate these possibilities, let’s consider an example. Suppose
a DPDA M with transition function δ is in state q, has a as its next
input symbol, and has symbol x on the top of its stack. If
δ(q,a,x)=(r,y) then M reads a, pops x off the stack, enters state r,
and pushes y on the stack.

Alternatively, if δ(q,a,x)=∅ then when M is in state q, it has
no move that reads a and pops x. In that case, the condition on δ
requires that one of δ(q,ε,x), δ(q,a,ε), or δ(q,ε,ε) is nonempty, and
then M moves accordingly. The condition enforces deterministic
behavior by preventing the DPDA from taking two different actions in
the same situation, such as would be the case if both δ(q,a,x)≠∅ and
δ(q,a,ε)≠∅.

A DPDA has exactly one legal move in every situation where its stack
is nonempty. If the stack is empty, a DPDA can move only if the
transition function specifies a move that pops ε. Otherwise the DPDA
has no legal move and it rejects without reading the rest of the
input.


LR(k) GRAMMARS
--------------

In an LR(k) grammar, a handle may also depend on symbols that follow
the handle, but only on the first k of these. The acronym LR(k) stands
for: L̫eft to right input processing, R̫ightmost derivations (or
equivalently, leftmost reductions), and k̫ symbols of lookahead.

To make this precise, let h be a handle of a valid string v=xhy. Say
that h is forced by lookahead k if h is the unique handle of every
valid string xhyͦ where yͦ∈Σ* and where y and yͦ agree on their first
k symbols. (If either string is shorter than k, the strings must agree
up to the length of the shorter one.)

An LR(k) grammar is a context-free grammar such that the handle of
every valid string is forced by lookahead k.
